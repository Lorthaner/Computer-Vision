# -*- coding: utf-8 -*-
"""MNIST_Classifier_Piotrek.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UfF9VO2YdslnAwPOsq50TUHwh7pI23uM
"""

import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as opt
import matplotlib.pyplot as plt
import numpy as np

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

trainset = torchvision.datasets.MNIST(root = './sample_data', train = True, download = True, transform = transforms.Compose([transforms.ToTensor(),
                                                                                                                                        transforms.Normalize(0.1307, 0.3081)]))

testset = torchvision.datasets.MNIST(root = './sample_data', train = False, transform = transforms.Compose([transforms.ToTensor(),
                                                                                               transforms.Normalize(0.1307, 0.3081)]))

img, label = trainset[1]

img.view(-1).shape

plt.imshow(img.squeeze(), cmap = 'gray')

train_loader = torch.utils.data.DataLoader(trainset, batch_size = 100, shuffle = True)
test_loader = torch.utils.data.DataLoader(testset, batch_size = 100, shuffle = True)

len(train_loader)

class MLP(nn.Module):
  
  def __init__(self, input = 784, output = 10):
    super().__init__()
    self.inp = nn.Linear(input, 120)
    self.fc1 = nn.Linear(120,200)
    self.fc2 = nn.Linear(200,120)
    self.out = nn.Linear(120,output)

  def forward(self,x):

    x = F.relu(self.inp(x))
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.out(x)

    return x

model = MLP()

model = model.to(device)

def training_loop(epochs, learning_rate):

    criterion = nn.CrossEntropyLoss()
    optimizer = opt.SGD(model.parameters(),lr = learning_rate)

    for epoch in range(epochs):
      correct = 0
      total = 0
      for i, data in enumerate(train_loader, 0):
              # get the inputs; data is a list of [inputs, labels]
            images, labels = data[0].to(device), data[1].to(device)

            optimizer.zero_grad()
            model_predictions= model(images.view(100,-1))
            loss = criterion(model_predictions, labels)
            loss.backward()
            optimizer.step()

            _, predicted = torch.max(model_predictions, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
      accuracy = 100 * correct / total
      print("Accuracy = {}".format(accuracy))


    print('Finished Training')

training_loop(15,0.03)

correct_test = 0
total_test = 0
with torch.no_grad():
    for data_test in test_loader:
       images_test, labels_test  = data_test[0].to(device), data_test[1].to(device)
       outputs = model(images_test.view(100,-1))
       _,predicted_test = torch.max(outputs.data,1)
       total_test += labels_test.size(0)
       correct_test += (predicted_test == labels_test).sum().item()
print(f'Test_accuracy:{100 * correct_test / total_test}%')