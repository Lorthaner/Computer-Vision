# -*- coding: utf-8 -*-
"""CIFAR10_model_1_Piotrek.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UfF9VO2YdslnAwPOsq50TUHwh7pI23uM
"""

import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as opt
import matplotlib.pyplot as plt
import numpy as np
from mpl_toolkits.axes_grid1 import ImageGrid

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

trainset = torchvision.datasets.CIFAR10(root = './sample_data', train = True, download = True, transform = transforms.Compose([transforms.ToTensor(),
                                                                                                                                        transforms.Normalize(0.4914, 0.4822, 0.4465)]))

testset = torchvision.datasets.CIFAR10(root = './sample_data', train = False, transform = transforms.Compose([transforms.ToTensor(),
                                                                                               transforms.Normalize(0.4914, 0.4822, 0.4465)]))

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

train_loader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)
test_loader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True)

dataiter = iter(train_loader)
images, labels = dataiter.next()
img_grid = torchvision.utils.make_grid(images[0:4])
plt.imshow(img_grid.permute(1,2,0))
print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))

class CIFAR10(nn.Module):
  
  def __init__(self):
    super().__init__()
    self.sequential = nn.Sequential(
        nn.Conv2d(3,32,3, padding = 1),
        nn.ReLU(),
        nn.Conv2d(32,32,3, padding = 1),
        nn.ReLU(),
        nn.Conv2d(32,32,3, padding = 1),
        nn.MaxPool2d(2,2),  # 32 , 16 , 16
        nn.Dropout(0.2),
        nn.Conv2d(32,64,3, padding = 1),
        nn.ReLU(),
        nn.Conv2d(64,64,3, padding = 1),
        nn.ReLU(),
        nn.Conv2d(64,64,3, padding = 1),
        nn.MaxPool2d(2,2),  # 64, 8 , 8
        nn.Dropout(0.3),
        nn.Conv2d(64,128,3, padding = 1),
        nn.ReLU(),
        nn.Conv2d(128,128,3, padding = 1),
        nn.ReLU(),
        nn.Conv2d(128,128,3, padding = 1),
        nn.MaxPool2d(2,2), # 128, 4, 4
        nn.Dropout(0.4),
        nn.Flatten(),
        nn.Linear(128*4*4,64),
        nn.Linear(64,32),
        nn.Linear(32,10)
    )

  def forward(self,x):
      return self.sequential(x)

model = CIFAR10().to(device)

def training_loop(epochs, learning_rate, weight_decay):

    criterion = nn.CrossEntropyLoss()
    optimizer = opt.Adam(model.parameters(),lr = learning_rate, weight_decay=weight_decay)

    for epoch in range(epochs):
      correct = 0
      total = 0
      for i, data in enumerate(train_loader, 0):
              # get the inputs; data is a list of [inputs, labels]
            images, labels = data[0].to(device), data[1].to(device)

            optimizer.zero_grad()
            model_predictions= model(images)
            loss = criterion(model_predictions, labels)
            loss.backward()
            optimizer.step()

            _, predicted = torch.max(model_predictions, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
      accuracy = 100 * correct / total
      print("Accuracy = {} , Epoch = {}, Loss = {}".format(accuracy,epoch+1, loss))
      correct_test = 0
      total_test = 0
      with torch.no_grad():
          for data_test in test_loader:
            images_test, labels_test  = data_test[0].to(device), data_test[1].to(device)
            outputs = model(images_test)
            _,predicted_test = torch.max(outputs.data,1)
            total_test += labels_test.size(0)
            correct_test += (predicted_test == labels_test).sum().item()
      print(f'Test_accuracy:{100 * correct_test / total_test}%')

    print('Finished Training')

training_loop(40,0.0005,1e-5)